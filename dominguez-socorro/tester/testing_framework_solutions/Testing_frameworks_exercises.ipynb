{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e618a65-ddba-4f8b-b4bb-01d98d26dc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from importlib.machinery import SourceFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2025ef71-01b9-4437-a2b5-d09959bc18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign import sign\n",
    "import  test_sign as ts\n",
    "import find_tests as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5a6ac-b834-4346-890f-99d4162d8dbe",
   "metadata": {},
   "source": [
    "### Q1. What happens if you run:\n",
    "\n",
    "```python\n",
    "for name in globals():\n",
    "    print(name)\n",
    "```\n",
    "\n",
    "What happens if you run:\n",
    "\n",
    "```python\n",
    "name = None\n",
    "for name in globals():\n",
    "    print(name)\n",
    "```\n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118231a-8b47-42ec-bd95-ecf93f902bc8",
   "metadata": {},
   "source": [
    "\n",
    "First, before running any `for` loop, I would like to take a look at what `globals()` is. `globals()` returns a dictionary with all the available variables. \n",
    "\n",
    "When you define `name` as None, you are basically doing:\n",
    "globals()[name] = None, so you are appending that new variable into your `globals()` dictionary. Because of this, the for loop can run. \n",
    "\n",
    "When you run the `for` loop, without having defined `name=None`, you are grabing the `globals` dictionary and checking its length before iterating over it. Then, you proceed to print the name of each key. However, because you are creating a new \"temporary\" variable called `name` that is appended directly to `globals()[name]` in the first call, you are modifying the dictionary `globals()` and so, are not iterating over the \"same\" globals where your first iteration happened. \n",
    "\n",
    "Even if you did `name=None`, if you reran the `for` loop but now did `name2` instead of `name`, you would face the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafe80bb-4d97-460e-af24-0c377df04100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7ace2-60d8-4113-88af-75236af60403",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a028a-11f8-47cb-89a4-25a11dd671d0",
   "metadata": {},
   "source": [
    "1.  Modify the test framework so that it reports which tests passed, failed, or had errors and also reports a summary of how many tests produced each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11551f70-4a28-47ec-b827-2c59aea28b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass': ['test_sign_assert', 'test_sign_negative', 'test_sign_positive'],\n",
       " 'fail': ['test_sign_assert2', 'test_sign_zero'],\n",
       " 'error': ['test_sign_error'],\n",
       " 'summary': {'pass': 3, 'fail': 2, 'error': 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script is find_tests.py\n",
    "ft.find_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27ccb7-d9d3-4837-a2a8-1de260269de7",
   "metadata": {},
   "source": [
    "2.  Write unit tests to check that your answer to part 1 works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b932fa-5667-4baa-8b41-4f9430538d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass': ['test_sign_assert', 'test_sign_negative', 'test_sign_positive'],\n",
       " 'fail': ['test_sign_assert2', 'test_sign_zero'],\n",
       " 'error': ['test_sign_error'],\n",
       " 'summary': {'pass': 3, 'fail': 2, 'error': 1}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ft.find_tests()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544ef9d9-0ffb-4591-b821-09dca5f04ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(results['pass']) == results['summary']['pass'], \"These two keys are related, are you appending in the summary the right value?\"\n",
    "assert len(results['fail']) == results['summary']['fail'], \"These two keys are related, are you appending in the summary the right value?\"\n",
    "assert len(results['error']) == results['summary']['error'], \"These two keys are related, are you appending in the summary the right value?\"\n",
    "assert 'summary' in results.keys(), \"Did you append the summary in the right place?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e993381-0f81-4005-b4df-6aeb6e710fbe",
   "metadata": {},
   "source": [
    "3.  Think of another plausible way to interpret part 1\n",
    "    that *wouldn't* pass the tests you wrote for part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24def1-5350-4e01-a8b3-16dad57068a3",
   "metadata": {},
   "source": [
    "### Q3 Failing on Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e7155e-b828-4ed4-92fa-6a1439b4e393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass': ['test_sign_assert2', 'test_sign_negative', 'test_sign_positive'],\n",
       " 'fail': ['test_sign_assert', 'test_sign_zero'],\n",
       " 'error': ['test_sign_error'],\n",
       " 'summary': {'pass': 3, 'fail': 2, 'error': 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ft.find_tests_assert()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb433d1-6bd8-4e92-b033-88d5b4e041d0",
   "metadata": {},
   "source": [
    "- The test `test_sign_assert` does not raise an Assertion Error, hence it fails.   \n",
    "- The test `test_sign_assert2` produces an AssertionError and so, it passes.  \n",
    "- All other tests keep behaving the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b7880-a455-4111-b643-b108c3f3c4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Q4 Setup and Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e80b96a-0d43-4fc2-b991-5c31b94e5cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass': ['test_sign_assert2', 'test_sign_negative', 'test_sign_positive'],\n",
       " 'fail': ['test_sign_assert', 'test_sign_zero'],\n",
       " 'error': ['test_sign_error'],\n",
       " 'summary': {'pass': 3, 'fail': 2, 'error': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.find_tests_st()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
