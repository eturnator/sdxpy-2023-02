{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae8e710-e803-4e41-ae90-b750ccd2fb6a",
   "metadata": {},
   "source": [
    "# A Testing Framework: Exercises\n",
    "\n",
    "## Looping Over `globals`\n",
    "\n",
    "What happens if you run:\n",
    "\n",
    "```python\n",
    "for name in globals():\n",
    "    print(name)\n",
    "```\n",
    "\n",
    "What happens if you run:\n",
    "\n",
    "```python\n",
    "name = None\n",
    "for name in globals():\n",
    "    print(name)\n",
    "```\n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc16702-f140-477f-9f3f-e9ef4c8244bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "for name in globals():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed070ef-087f-4cef-bac1-8b1621487cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__\n",
      "__doc__\n",
      "__package__\n",
      "__loader__\n",
      "__spec__\n",
      "__builtin__\n",
      "__builtins__\n",
      "_ih\n",
      "_oh\n",
      "_dh\n",
      "In\n",
      "Out\n",
      "get_ipython\n",
      "exit\n",
      "quit\n",
      "open\n",
      "_\n",
      "__\n",
      "___\n",
      "_i\n",
      "_ii\n",
      "_iii\n",
      "_i1\n",
      "name\n",
      "_i2\n"
     ]
    }
   ],
   "source": [
    "name = None\n",
    "for name in globals():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6dc08-b5ee-4364-9d0f-b645f324ef24",
   "metadata": {},
   "source": [
    "In the first code chunk you are trying to iterate over and modify an object (i.e., dictionary returned by `globals()`) at the same time. The second code chunk doesn't raise a `RuntimeError` because `name` has a global scope to begin with and is not introduced to the global space during the for-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a73f30-11e7-47aa-9319-044a5d7d599c",
   "metadata": {},
   "source": [
    "## Counting Results\n",
    "\n",
    "1.  Modify the test framework so that it reports which tests passed, failed, or had errors\n",
    "    and also reports a summary of how many tests produced each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfdd8ec2-78b7-4c55-9d48-19d583e60fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from lecture slides\n",
    "def sign(value):\n",
    "    if value < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def test_sign_negative():\n",
    "    assert sign(-3) == -1\n",
    "def test_sign_positive():\n",
    "    assert sign(19) == 1\n",
    "def test_sign_zero():\n",
    "    assert sign(0) == 0\n",
    "def test_sign_error():\n",
    "    assert sgn(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba6b137b-f113-4523-a7b5-a5098c6e0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from lecture slides\n",
    "TESTS = [\n",
    "    test_sign_negative,\n",
    "    test_sign_positive,\n",
    "    test_sign_zero,\n",
    "    test_sign_error\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33b1e9e-aba2-4c9f-9033-18451da71034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified function from slide 12\n",
    "def run_tests(all_tests):\n",
    "    results = {\"pass\": [], \"fail\": [], \"error\": []}\n",
    "    for test in all_tests:\n",
    "        try:\n",
    "            test()\n",
    "            results[\"pass\"].append(test.__name__)\n",
    "        except AssertionError:\n",
    "            results[\"fail\"].append(test.__name__)\n",
    "        except Exception:\n",
    "            results[\"error\"].append(test.__name__)\n",
    "    \n",
    "    results['summary'] = {'pass': len(results['pass']),\n",
    "                          'fail': len(results['fail']),\n",
    "                          'error': len(results['error'])}\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4ce3b-4f8c-4970-ad61-1555b040671a",
   "metadata": {},
   "source": [
    "2.  Write unit tests to check that your answer to part 1 works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36801d9a-0f7a-4289-b196-6e088dd09fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_tests(TESTS)\n",
    "\n",
    "# dictionary has correct length\n",
    "def test_dict_len():\n",
    "    assert len(result) == 4\n",
    "\n",
    "# outer dictionary has expected keys\n",
    "def test_outer_dict():\n",
    "    assert result.keys() == {'pass', 'fail', 'error', 'summary'}\n",
    "    \n",
    "# inner dictionary has expected keys\n",
    "def test_outer_dict():\n",
    "    assert result['summary'].keys() == {'pass', 'fail', 'error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbe1dfb-ee31-46cc-a9bc-c96e3d97ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict_len()\n",
    "test_outer_dict()\n",
    "test_outer_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047be4d-8cd8-4009-95b1-093c3d3e49e9",
   "metadata": {},
   "source": [
    "3.  Think of another plausible way to interpret part 1\n",
    "    that *wouldn't* pass the tests you wrote for part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28612c8f-8469-46c2-8ac7-b2ef9c4d92b5",
   "metadata": {},
   "source": [
    "Using `print()` instead of `return()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecb010-3e80-477e-84a8-5f1c70c446d4",
   "metadata": {},
   "source": [
    "## Failing on Purpose\n",
    "\n",
    "Putting assertions into code to check that it is behaving correctly\n",
    "is called __defensive programming__.\n",
    "It's a good practice,\n",
    "but we should make sure those assertions are failing when they're supposed to,\n",
    "just as we should test our smoke detectors every once in a while.\n",
    "\n",
    "Modify the tester so that\n",
    "if a test function's docstring is `\"test:assert\"`,\n",
    "the test passes if it raises an `AssertionError`\n",
    "and fails if it does not.\n",
    "Tests whose docstring don't contain `\"test:assert\"`\n",
    "should behave as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780ae0d6-1ec0-4891-92be-985bcd6dae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(all_tests):\n",
    "    results = {\"pass\": [], \"fail\": [], \"error\": []}\n",
    "    for test in all_tests:\n",
    "        if (test.__doc__ == \"test:assert\"): \n",
    "            try:\n",
    "                test()\n",
    "            except AssertionError:\n",
    "                results[\"pass\"].append(test.__name__)\n",
    "            else:\n",
    "                results[\"fail\"].append(test.__name__)\n",
    "        else:\n",
    "            try:\n",
    "                test()\n",
    "                results[\"pass\"].append(test.__name__)\n",
    "            except AssertionError:\n",
    "                results[\"fail\"].append(test.__name__)\n",
    "            except Exception:\n",
    "                results[\"error\"].append(test.__name__)\n",
    "    \n",
    "    results['summary'] = {'pass': len(results['pass']),\n",
    "                          'fail': len(results['fail']),\n",
    "                          'error': len(results['error'])}\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b23fe-8252-47f0-b825-77650169e9bc",
   "metadata": {},
   "source": [
    "## Setup and Teardown\n",
    "\n",
    "Testing frameworks often allow programmers to specify a `setup` function\n",
    "that is to be run before each test\n",
    "and a corresponding `teardown` function\n",
    "that is to be run after each test.\n",
    "(`setup` usually re-creates complicated test fixtures,\n",
    "while `teardown` functions are sometimes needed to clean up after tests,\n",
    "e.g., to close database connections or delete temporary files.)\n",
    "\n",
    "Modify the testing tool in this chapter so that\n",
    "if a file of tests contains a function called `setup`\n",
    "then the tool calls it exactly once before running each test in the file.\n",
    "Add a similar way to register a `teardown` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc7658e-5df5-48eb-81a1-70a085287cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    results = {\"pass\": [], \"fail\": [], \"error\": []}\n",
    "    for (name, test) in globals().items():\n",
    "        if not name.startswith(\"test_\"):\n",
    "            continue\n",
    "            \n",
    "        if \"setup\" in globals():\n",
    "            setup()\n",
    "        \n",
    "        if (test.__doc__ == \"test:assert\"):\n",
    "            try:\n",
    "                test()\n",
    "            except AssertionError:\n",
    "                results[\"pass\"].append(test.__name__)\n",
    "            else:\n",
    "                results[\"fail\"].append(test.__name__)\n",
    "                \n",
    "        else:\n",
    "            try:\n",
    "                test()\n",
    "                results[\"pass\"].append(test.__name__)\n",
    "            except AssertionError:\n",
    "                results[\"fail\"].append(test.__name__)\n",
    "            except Exception:\n",
    "                results[\"error\"].append(test.__name__)\n",
    "                \n",
    "        if \"teardown\" in globals():\n",
    "            teardown()\n",
    "        \n",
    "    results['summary'] = {'pass': len(results['pass']),\n",
    "                          'fail': len(results['fail']),\n",
    "                          'error': len(results['error'])}\n",
    "    return(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
